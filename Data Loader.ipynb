{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import re \n",
    "import gc \n",
    "import os \n",
    "import cv2\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "DATA_PATH = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/train_image_data_3.parquet', 'data/test_image_data_0.parquet', 'data/class_map.csv', 'data/test_image_data_2.parquet', 'data/bengaliai-cv19.zip', 'data/sample_submission.csv', 'data/train_image_data_0.parquet', 'data/train.csv', 'data/train_image_data_1.parquet', 'data/train_image_data_2.parquet', 'data/test.csv', 'data/test_image_data_3.parquet', 'data/test_image_data_1.parquet']\n"
     ]
    }
   ],
   "source": [
    "FILES = os.listdir(DATA_PATH)\n",
    "FILES = [os.path.join(DATA_PATH,file) for file in FILES]\n",
    "print(FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data load \n",
    "labels = ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']\n",
    "train_data = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', 'grapheme_root', 'vowel_diacritic', 'consonant_diacritic',\n",
       "       'grapheme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data desc\n",
    "train_data.shape\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grapheme root unique \n",
    "root_uq = len(np.unique(train_data.grapheme_root))\n",
    "#Vowel diactric \n",
    "vow_uq = len(np.unique(train_data.vowel_diacritic))\n",
    "#Consonant diactritic \n",
    "con_uq = len(np.unique(train_data.consonant_diacritic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ROOT UQ 168\n",
      "Unique VOW  UQ 11\n",
      "Unique CON  UQ 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique ROOT UQ {}\".format(root_uq))\n",
    "print(\"Unique VOW  UQ {}\".format(vow_uq))\n",
    "print(\"Unique CON  UQ {}\".format(con_uq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(df, size=64, need_progress_bar=True):\n",
    "    resized = {}\n",
    "    for i in range(df.shape[0]):\n",
    "        image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\n",
    "        resized[df.index[i]] = image.reshape(-1)\n",
    "    resized = pd.DataFrame(resized).T\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_image_0 = pd.read_parquet('data/train_image_data_0.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional packages\n",
    "#!pip install pyarrow\n",
    "#!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_train_data = pd.merge(pd.read_parquet('data/train_image_data_0.parquet'), \n",
    "                       train_data, on = 'image_id').drop(['image_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = b_train_data.drop(labels, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH =  137, 236 \n",
    "images = train_data.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "def crop_resize(img0, size=64, pad=16):\n",
    "    #crop a box around pixels large than the threshold \n",
    "    #some images contain line at the sides\n",
    "    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
    "    #cropping may cut too much, so we need to add it back\n",
    "    xmin = xmin - 13 if (xmin > 13) else 0\n",
    "    ymin = ymin - 10 if (ymin > 10) else 0\n",
    "    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n",
    "    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n",
    "    img = img0[ymin:ymax,xmin:xmax]\n",
    "    #remove lo intensity pixels as noise\n",
    "    img[img < 28] = 0\n",
    "    lx, ly = xmax-xmin,ymax-ymin\n",
    "    l = max(lx,ly) + pad\n",
    "    #make sure that the aspect ratio is kept in rescaling\n",
    "    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
    "    return cv2.resize(img,(size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bengali",
   "language": "python",
   "name": "bengali"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
